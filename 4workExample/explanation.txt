This segment is designed to walk through how to develop, test and deploy with docker.

It'll also go through how we re-develop, re-test and re-deploy for a development lifecycle

Example flow.

> You push code to github feature branch in a repo.
> You then make a pull request against the main branch
> a montioring service will take this code in master / main branch and run 
	all the tests you designed for it.
	For the sake of this demo, it'll be using travis ci
> Once it's fully passed all those tests, it'll auto push this to AWS host

=====================================

NOTE - docker isn't needed for these workflows. It is a tool to make
	executing some of these tasks so much easier

=====================================

This'll use a react app.

npm run start
npm run test
npm run build 

====================================

We have 2 docker files, 1 for dev, one for production.

To specify another docker file to build, we use the -f argument

"docker build -f Dockerfile.dev ."

=====================================

We deleted our local node_modules directory as the "copy" command was copying all the node module over
after we just told docker to install them onto the container

===================================

Problem - changes in source code didn't propagate onto running container

( note - if we want to solve this, we can't use the copy, we need to use something called 'volumes' )

Volume - A volume is similar to port mapping. We essentially map a folder in the contianer to outside the container

"docker run -p 3000:3000 -v /app/node_modules -v $(pwd):/app <image>"

the -v flag is the volume mapping.

-v /app/node_modules 	<-- essentially saying, map node modules from the container to our local pwd /node_modules
-v $(pwd):/app 			<-- Saying map out current working directory to the /app directory in the container


================================

Because the docker run file was so long, we made a docker-compose file.yml file to contain all the cmdline arguments instead

================================

When trying to run the "npm run test", we need to run the docker file with the -it argument and the command we want to run.

"docker build ."
"docker run -it <image id> npm run test"

------------------------------

There was a slight problem here in that, running the tests doesn't update if we create more tests

A quick solution was to run the docker compose file, bring up the build.
Then use the image id of that running container and send it a "npm run tests"
"docker exec -it <docker_compose image id> npm run test"
## This isn't optimal as it requires us to build the docker compose file

The second solution is to create a second service inside the docker-compose file.
We added a second command to the docker compose file, then got it to rebuild with the command
"docker-compose up --build"
This is also not great because it gets the stdout & stdin mixed up with the other service from docker-compose file

We tried using another terminal to docker attach to the running container, but this doesn't work.
Docker-compose doesn't allow us to run the tests essentially - 
Reason : When we tried to attach the terminal ("docker attach <test_contianer_id>"), it attaches to the stdin of the primary process
The npm run tests command creates 1 process for 'npm' then npm starts a second process for the 'npm run tests'
Because of this, when we try to attach to the docker container, we only attach to npm, so our input is essentially discarded

====================================
Docker build - production version of web container

Going to mkae use of nginx - it's a webserver that just routes static files

# note - one of the differences between this and the dev build is that we don't need all the dependencies to run the docker file
# We just need the contents of the ./build directory -- this will eliminate ~150mb of garbage

We can use something called a "multi-step build process".
It'll have 2 different blocks of configuration.
1. will be for the build phase - install dependences, run the build command e.t.called
2. Is for the run phase - This will allow a second base image, and allows us to copy the results of #1 to this container and allow us to run nginx

-------------------
We made the Dockerfile that contains the builder and run phases for the container.

When we 'docker build' and 'docker run', we have a very sturdy webserver because of nginx.
Nginx is a very solid webserver and is made for production environments.
